{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QshK8s21WBrf"
   },
   "source": [
    "# HW09\n",
    "\n",
    "## Exercises to practice unsupervised learning, clustering and PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hf8SXUwWOho"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the following 2 cells to import all necessary libraries and helpers for this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/data_utils.py\n",
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/image_utils.py\n",
    "!wget -q https://github.com/DM-GY-9103-2024F-H/HW08/raw/main/HW08_utils.pyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from os import listdir, path\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from data_utils import object_from_json_url\n",
    "from data_utils import StandardScaler\n",
    "from data_utils import KMeansClustering, GaussianClustering, SpectralClustering\n",
    "\n",
    "from data_utils import PCA, RandomForestClassifier, SVC\n",
    "from data_utils import classification_error, display_confusion_matrix\n",
    "\n",
    "from image_utils import make_image, open_image\n",
    "\n",
    "from HW08_utils import CamUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "Let's load up the full [ANSUR](https://www.openlab.psu.edu/ansur2/) dataset that we looked at briefly in [Week 02](https://github.com/DM-GY-9103-2024F-H/WK02) and then again in [HW08](https://github.com/DM-GY-9103-2024F-H/HW08) last week.\n",
    "\n",
    "This is the dataset that has anthropometric information about U.S. Army personnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'age': 18,\n",
       "  'gender': 'F',\n",
       "  'height': 66,\n",
       "  'weight': 135,\n",
       "  'span': 1699,\n",
       "  'stature': 1645,\n",
       "  'ear': {'breadth': 30, 'length': 61, 'protrusion': 20},\n",
       "  'foot': {'breadth': 97, 'length': 243},\n",
       "  'hand': {'breadth': 78, 'length': 182, 'palm': 108},\n",
       "  'head': {'height': 243, 'circumference': 557}},\n",
       " {'age': 30,\n",
       "  'gender': 'M',\n",
       "  'height': 68,\n",
       "  'weight': 207,\n",
       "  'span': 1749,\n",
       "  'stature': 1715,\n",
       "  'ear': {'breadth': 35, 'length': 63, 'protrusion': 17},\n",
       "  'foot': {'breadth': 100, 'length': 252},\n",
       "  'hand': {'breadth': 87, 'length': 184, 'palm': 114},\n",
       "  'head': {'height': 238, 'circumference': 560}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataset\n",
    "ANSUR_FILE = \"https://raw.githubusercontent.com/DM-GY-9103-2024F-H/9103-utils/main/datasets/json/ansur.json\"\n",
    "ansur_data = object_from_json_url(ANSUR_FILE)\n",
    "\n",
    "# Look at first 2 records\n",
    "ansur_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load it into a `DataFrame`, like last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>span</th>\n",
       "      <th>stature</th>\n",
       "      <th>ear.breadth</th>\n",
       "      <th>ear.length</th>\n",
       "      <th>ear.protrusion</th>\n",
       "      <th>foot.breadth</th>\n",
       "      <th>foot.length</th>\n",
       "      <th>hand.breadth</th>\n",
       "      <th>hand.length</th>\n",
       "      <th>hand.palm</th>\n",
       "      <th>head.height</th>\n",
       "      <th>head.circumference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>F</td>\n",
       "      <td>66</td>\n",
       "      <td>135</td>\n",
       "      <td>1699</td>\n",
       "      <td>1645</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>20</td>\n",
       "      <td>97</td>\n",
       "      <td>243</td>\n",
       "      <td>78</td>\n",
       "      <td>182</td>\n",
       "      <td>108</td>\n",
       "      <td>243</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>68</td>\n",
       "      <td>207</td>\n",
       "      <td>1749</td>\n",
       "      <td>1715</td>\n",
       "      <td>35</td>\n",
       "      <td>63</td>\n",
       "      <td>17</td>\n",
       "      <td>100</td>\n",
       "      <td>252</td>\n",
       "      <td>87</td>\n",
       "      <td>184</td>\n",
       "      <td>114</td>\n",
       "      <td>238</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>M</td>\n",
       "      <td>67</td>\n",
       "      <td>121</td>\n",
       "      <td>1684</td>\n",
       "      <td>1657</td>\n",
       "      <td>36</td>\n",
       "      <td>59</td>\n",
       "      <td>24</td>\n",
       "      <td>92</td>\n",
       "      <td>251</td>\n",
       "      <td>84</td>\n",
       "      <td>180</td>\n",
       "      <td>103</td>\n",
       "      <td>239</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>73</td>\n",
       "      <td>185</td>\n",
       "      <td>1878</td>\n",
       "      <td>1828</td>\n",
       "      <td>36</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>104</td>\n",
       "      <td>280</td>\n",
       "      <td>95</td>\n",
       "      <td>201</td>\n",
       "      <td>124</td>\n",
       "      <td>270</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>M</td>\n",
       "      <td>76</td>\n",
       "      <td>150</td>\n",
       "      <td>1977</td>\n",
       "      <td>1883</td>\n",
       "      <td>39</td>\n",
       "      <td>65</td>\n",
       "      <td>27</td>\n",
       "      <td>101</td>\n",
       "      <td>271</td>\n",
       "      <td>90</td>\n",
       "      <td>194</td>\n",
       "      <td>113</td>\n",
       "      <td>254</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age gender  height  weight  span  stature  ear.breadth  ear.length  \\\n",
       "0   18      F      66     135  1699     1645           30          61   \n",
       "1   30      M      68     207  1749     1715           35          63   \n",
       "2   27      M      67     121  1684     1657           36          59   \n",
       "3   20      M      73     185  1878     1828           36          60   \n",
       "4   33      M      76     150  1977     1883           39          65   \n",
       "\n",
       "   ear.protrusion  foot.breadth  foot.length  hand.breadth  hand.length  \\\n",
       "0              20            97          243            78          182   \n",
       "1              17           100          252            87          184   \n",
       "2              24            92          251            84          180   \n",
       "3              21           104          280            95          201   \n",
       "4              27           101          271            90          194   \n",
       "\n",
       "   hand.palm  head.height  head.circumference  \n",
       "0        108          243                 557  \n",
       "1        114          238                 560  \n",
       "2        103          239                 516  \n",
       "3        124          270                 582  \n",
       "4        113          254                 559  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read into DataFrame\n",
    "ansur_df = pd.json_normalize(ansur_data)\n",
    "ansur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning\n",
    "\n",
    "Let's pretend we are designing next-generation helmets with embedded over-the-ear headphones and we want to have a few options for sizes.\n",
    "\n",
    "We could use clustering to see if there is a number of clusters that we can divide our population into, so each size covers a similar portion of the population.\n",
    "\n",
    "We can follow similar steps to regression to create a clustering model that uses features about head and ear sizes:\n",
    "\n",
    "1. Load dataset (done! ðŸŽ‰)\n",
    "2. Encode label features as numbers\n",
    "3. Normalize the data\n",
    "4. Separate the feature variables we want to consider (done below)\n",
    "5. Pick a clustering algorithm\n",
    "6. Determine number of clusters\n",
    "7. Cluster data\n",
    "8. Interpret results\n",
    "\n",
    "For step $5$, it's fine to just pick an algorithm ahead of time to see what happens, but feel free to experiment and plot results for multiple clustering methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1. 0. 0. ... 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m gender_order \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m gender_encoder \u001b[38;5;241m=\u001b[39m OrdinalEncoder(categories\u001b[38;5;241m=\u001b[39m[[gender_order]])\n\u001b[0;32m----> 5\u001b[0m gender_vals \u001b[38;5;241m=\u001b[39m \u001b[43mgender_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mansur_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgender\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m ansur_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m gender_vals\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m## Normalize the data\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    322\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1084\u001b[0m             (\n\u001b[1;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1094\u001b[0m         )\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:1496\u001b[0m, in \u001b[0;36mOrdinalEncoder.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1490\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown_value should only be set when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandle_unknown is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_encoded_value\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1492\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munknown_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1493\u001b[0m     )\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;66;03m# `_fit` will only raise an error when `self.handle_unknown=\"error\"`\u001b[39;00m\n\u001b[0;32m-> 1496\u001b[0m fit_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_and_ignore_missing_for_infrequent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_missing_indices \u001b[38;5;241m=\u001b[39m fit_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing_indices\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1504\u001b[0m cardinalities \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(categories) \u001b[38;5;28;01mfor\u001b[39;00m categories \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories_]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:79\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[0;34m(self, X, handle_unknown, force_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 79\u001b[0m X_list, n_samples, n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m n_features\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:45\u001b[0m, in \u001b[0;36m_BaseEncoder._check_X\u001b[0;34m(self, X, force_all_finite)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mPerform custom check_array:\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m- convert list of strings to object dtype\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# if not a dataframe, do normal check_array validation\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     X_temp \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(X_temp\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mstr_):\n\u001b[1;32m     47\u001b[0m         X \u001b[38;5;241m=\u001b[39m check_array(X, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m, force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1050\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1045\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1046\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1047\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1049\u001b[0m             )\n\u001b[0;32m-> 1050\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1056\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1. 0. 0. ... 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "## Encode non-numerical features\n",
    "## i did onehot in last week's homework, so will practice with ordinal even though gender isn't hierarchical\n",
    "gender_order = [\"M\", \"F\"]\n",
    "gender_encoder = OrdinalEncoder(categories=[[gender_order]])\n",
    "gender_vals = gender_encoder.fit_transform(ansur_df[\"gender\"].values)\n",
    "ansur_df[\"gender\"] = gender_vals\n",
    "\n",
    "## Normalize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate the features we want to consider\n",
    "ansur_features = ansur_scaled_df[[\"head.height\", \"head.circumference\", \"ear.length\", \"ear.breadth\", \"ear.protrusion\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Create Clustering model\n",
    "\n",
    "## Run the model(s) on the data\n",
    "\n",
    "## Check errors\n",
    "\n",
    "## Plot clusters as function of 2 or 3 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Which clustering algorithm did you choose?<br>\n",
    "Did you try a different one?<br>\n",
    "Do the clusters make sense ? Do they look balanced ?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out how many cluster\n",
    "\n",
    "Experiment with the number of clusters to see if the initial choice makes sense.\n",
    "\n",
    "The [WK09](https://github.com/DM-GY-9103-2024F-H/WK09) notebook had a for loop that can be used to plot errors versus number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Plot errors and pick how many cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Based on the graphs of errors versus number of clusters, does it look like we should change the initial number of clusters ?<br>\n",
    "How many clusters should we use ? Why ?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revise Number of Clusters.\n",
    "\n",
    "Re-run with the new number of clusters and plot the data in $2D$ or $3D$.\n",
    "\n",
    "This can be the same graph as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Re-run clustering with final number of clusters\n",
    "\n",
    "## Run the model on the training data\n",
    "\n",
    "## Check errors\n",
    "\n",
    "## Plot in 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Do these look better than the original number of clusters?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA and Classification\n",
    "\n",
    "Let's practice doing some more image classification with `PCA` and analyzing the results.\n",
    "\n",
    "The dataset is the same as last week. It has images from $25$ different security cameras, and our task is to separate them by camera. Some of the cameras move, some of them don't, and there are more than $1000$ images, so there's no way we want to do this by hand.\n",
    "\n",
    "Let's start by loading the training images into a list of pixels, like we did with the `faces` dataset in class.\n",
    "\n",
    "### Loading Data\n",
    "\n",
    "If we look at the images in `./data/images/0801-500/train/`, we'll notice that they are named and organized in a slightly different way. They're all in the same directory and the first part of their filename specifies which camera they came from. Even though those `ids` are numbers, they're not sequential, so we'll use some helper functions to extract a unique `label` from their filenames.\n",
    "\n",
    "This is exactly what the `OrdinalEncoder` class does, but since we only have to encode this one column, we'll do it by hand while we read the files in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates a list of all the files in a given directory, that end in .jpg\n",
    "train_files = [f for f in listdir(\"./data/images/0801-500/train\") if f.endswith(\".jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: check and see what is inside the list here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll read the image pixels and extract their labels. `CamUtils.get_label()` is the helper function we'll use to \"encode\" and return a label id based on the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_data = []\n",
    "label_data = []\n",
    "\n",
    "for fname in train_files:\n",
    "  label = CamUtils.get_label(fname)\n",
    "  img = open_image(path.join(\"./data/images/0801-500/train\", fname))\n",
    "  pixel_data.append(img.pixels)\n",
    "  label_data.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: check if labels got extracted correctly by looking at \n",
    "#       the first few items of the label list and the filename list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like last week, the labels and the filenames won't match exactly since labels start at $0$ and the filenames start at $01$ and skip some numbers.\n",
    "\n",
    "We can open some images from pixels, just to make sure we loaded them correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(make_image(pixel_data[0], width=256))\n",
    "display(make_image(pixel_data[10], width=256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "Create a `DataFrame` called `cam_pca_df` by running `PCA` on the list of pixel data, just like we did in class, and then append a `label` column to it, just like we did last week with: `train_df[\"label\"] = label_data`.\n",
    "\n",
    "You can change how many components to extract from the images later, but for this first run just use $10$ components so we can compare classification with $10$ `PCA` components to the classification with $10$ random features from `HW08`.  Make sure to confirm how much of the `variance` is preserved by this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: run PCA, get DataFrame\n",
    "# TODO: add \"label\" column\n",
    "# TODO: print variance\n",
    "# TODO: take a look at the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink\">\n",
    "How many components did you keep ?<br>\n",
    "Did you try different numbers ?<br>\n",
    "What percent of variance is kept by this transformation?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct\n",
    "\n",
    "Before we go run our classification, let's take a look at some reconstructed images, just to make sure they make sense.\n",
    "\n",
    "Take a look at reconstructed versions of images $0$, $10$, and whichever other images you might have opened above.\n",
    "\n",
    "We did this in class. It involves a `inverse_transform()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: reconstruct image at index 0\n",
    "\n",
    "# TODO: reconstruct image at index 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reconstructed images should look blurrier and noisier than the original ones, but they should still look something like the original ones.\n",
    "\n",
    "### Classify !\n",
    "\n",
    "Train a `RandomForestClassifier` on the `PCA` data.\n",
    "\n",
    "Remember to separate the output feature (`label`) from the input features (`PC0`, `PC1`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: create a classifier\n",
    "# TODO: split input and output features\n",
    "# TODO: fit the model\n",
    "# TODO: run predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Error\n",
    "\n",
    "For the train set we could use the generic `classification_error()` function that we've used before because we have the true labels for each file, but for measuring accuracy for our `test` set classification, which has secret labels, we have to use a more specific function from the `CamUtils` class.\n",
    "\n",
    "The function is called `classification_accuracy()` and it takes $2$ parameters, a list of filenames and the predicted labels associated with those filenames.\n",
    "\n",
    "The result is an accuracy score ratio, between $0.0$ and $1.0$.\n",
    "\n",
    "We can run this function on the `train` set as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_files is the list of files we got way up above\n",
    "CamUtils.classification_accuracy(train_files, train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink\">\n",
    "What does this mean?<br>\n",
    "Should we expect the same result from the test dataset?<br>\n",
    "Why, or why not?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on Test set\n",
    "\n",
    "Now we'll open the image files inside the `./data/images/0801-500/test/` directory, using almost the exact same steps as we did above to create a `DataFrame` with the exception that we don't have labels for these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: create a list of files in the test/ directory\n",
    "test_files = []\n",
    "\n",
    "# TODO: check its length and content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a similar loop to extract the pixel information from these images, except we don't have `label` data, just pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pixel_data = []\n",
    "\n",
    "for fname in test_files:\n",
    "  img = open_image(path.join(\"./data/images/0801-500/test\", fname))\n",
    "  test_pixel_data.append(img.pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run `PCA` and the `RandomForestClassifier`.\n",
    "\n",
    "Since those are already trained, all we have to do is run their `transform()` function on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: run PCA on test pixels, get DataFrame\n",
    "#       this is the same PCA that was created above, not a new one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always a good idea to check the result of the `PCA` transformation by looking at the `DataFrame` and reconstructing some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: reconstruct one or two images\n",
    "\n",
    "# TODO: take a look at the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink\"><br>\n",
    "The reconstructed images from the `test` set will always be noisier than the `train` images.<br><br>\n",
    "Why?<br><br>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Run the classifier and get predicted labels. Then get its accuracy ratio is by running the `CamUtils.classification_accuracy()` function with the list of filenames and list of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: run classifier. This is the same classifier already fitted on the train data above\n",
    "\n",
    "# TODO: get accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink\">\n",
    "What's the accuracy ? How could we improve that if we wanted ?<br>\n",
    "How does this compare to last week's classification model? They can both be tuned to perform well, but how many features did we need last week to get an accuracy comparable to this?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
